{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GUhT_xdVFXE"
      },
      "source": [
        "<h1>Advanced Machine Learning course - assignment No. 1</h1>\n",
        "<h2>Simone Paolo Mottadelli 820786</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3Q3jZEjV-I0"
      },
      "source": [
        "<hr>\n",
        "<h3>Configuration of the environment</h3>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgKw-hz3VEZN"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import tensorflow as tf\n",
        "import sklearn_pandas\n",
        "from sklearn import preprocessing\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential, Input, Model\n",
        "from keras.layers import Dense, Activation, LeakyReLU\n",
        "from keras.optimizers.schedules import ExponentialDecay\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "\n",
        "!pip install keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7HzLXxkXLJl"
      },
      "source": [
        "<hr>\n",
        "<h3>Import the dataset</h3>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aLNCmQ6WHRn"
      },
      "source": [
        "df_dataset = pd.read_csv(\"X_train.csv\")\n",
        "df_dataset = df_dataset.drop(columns=[\"Unnamed: 0\"])\n",
        "df_dataset[\"price\"] = pd.read_csv(\"y_train.csv\")[\"price\"]\n",
        "df_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiHQdH34bur1"
      },
      "source": [
        "<hr><h3>Dataset exploration</h3><hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFU1fLc8cL49"
      },
      "source": [
        "plt.figure(num=None, figsize=(20, 14), dpi=80, facecolor='w', edgecolor='k')\n",
        "\n",
        "plt.subplot(3, 3, 1)\n",
        "plt.hist(df_dataset[\"minimum_nights\"], bins=50)\n",
        "plt.title(\"minimum_nights\")\n",
        "\n",
        "plt.subplot(3, 3, 2)\n",
        "plt.hist(df_dataset[\"number_of_reviews\"], bins=50)\n",
        "plt.title(\"number_of_reviews\")\n",
        "\n",
        "plt.subplot(3, 3, 3)\n",
        "plt.hist(df_dataset[\"reviews_per_month\"], bins=50)\n",
        "plt.title(\"reviews_per_month\")\n",
        "\n",
        "plt.subplot(3, 3, 4)\n",
        "plt.hist(df_dataset[\"calculated_host_listings_count\"], bins=50)\n",
        "plt.title(\"calculated_host_listings_count\")\n",
        "\n",
        "plt.subplot(3, 3, 5)\n",
        "plt.hist(df_dataset[\"availability_365\"])\n",
        "plt.title(\"availability_365\")\n",
        "\n",
        "plt.subplot(3, 3, 6)\n",
        "plt.hist(df_dataset[\"Private_room\"])\n",
        "plt.title(\"Private_room\")\n",
        "\n",
        "plt.subplot(3, 3, 7)\n",
        "plt.hist(df_dataset[\"Entire_home/apt\"])\n",
        "plt.title(\"Entire_home/apt\")\n",
        "\n",
        "plt.subplot(3, 3, 8)\n",
        "plt.hist(df_dataset[\"price\"], 100)\n",
        "plt.title(\"price\")\n",
        "\n",
        "plt.subplot(3, 3, 9)\n",
        "plt.plot(df_dataset[\"latitude\"], df_dataset[\"longitude\"], \"ro\")\n",
        "plt.title(\"geo position\")\n",
        "plt.xlabel(\"latitude\")\n",
        "plt.ylabel(\"longitude\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3mJYkbItjgU"
      },
      "source": [
        "df_dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMWJUl4fhwiE"
      },
      "source": [
        "<hr><h3>Preprocessing</h3><hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zO0mc9ogp4h"
      },
      "source": [
        "# remove the rows where the price is too high (outliers)\n",
        "df_dataset = df_dataset.drop(df_dataset[df_dataset.price >= np.quantile(df_dataset[\"price\"], 0.96)].index)\n",
        "\n",
        "# remove the rows where the price is 0 (outliers)\n",
        "df_dataset = df_dataset.drop(df_dataset[df_dataset.price == 0].index)\n",
        "\n",
        "df_dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCcmVtvcd8ap"
      },
      "source": [
        "# apply log(x + 1) transformation and normalize between 0 and 1\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "df_dataset[\"minimum_nights\"] = np.log(df_dataset[\"minimum_nights\"] + 1)\n",
        "df_dataset[\"minimum_nights\"] = ((df_dataset[\"minimum_nights\"]-df_dataset[\"minimum_nights\"].min())/(df_dataset[\"minimum_nights\"].max()-df_dataset[\"minimum_nights\"].min()))\n",
        "\n",
        "df_dataset[\"number_of_reviews\"] = np.log(df_dataset[\"number_of_reviews\"] + 1)\n",
        "df_dataset[\"number_of_reviews\"] = ((df_dataset[\"number_of_reviews\"]-df_dataset[\"number_of_reviews\"].min())/(df_dataset[\"number_of_reviews\"].max()-df_dataset[\"number_of_reviews\"].min()))\n",
        "\n",
        "df_dataset[\"reviews_per_month\"] = np.log(df_dataset[\"reviews_per_month\"] + 1)\n",
        "df_dataset[\"reviews_per_month\"] = ((df_dataset[\"reviews_per_month\"]-df_dataset[\"reviews_per_month\"].min())/(df_dataset[\"reviews_per_month\"].max()-df_dataset[\"reviews_per_month\"].min()))\n",
        "\n",
        "df_dataset[\"calculated_host_listings_count\"] = np.log(df_dataset[\"calculated_host_listings_count\"] + 1)\n",
        "df_dataset[\"calculated_host_listings_count\"] = ((df_dataset[\"calculated_host_listings_count\"]-df_dataset[\"calculated_host_listings_count\"].min())/(df_dataset[\"calculated_host_listings_count\"].max()-df_dataset[\"calculated_host_listings_count\"].min()))\n",
        "\n",
        "df_dataset[\"availability_365\"] = np.log(df_dataset[\"availability_365\"] + 1)\n",
        "df_dataset[\"availability_365\"] = ((df_dataset[\"availability_365\"]-df_dataset[\"availability_365\"].min())/(df_dataset[\"availability_365\"].max()-df_dataset[\"availability_365\"].min()))\n",
        "\n",
        "df_dataset[\"latitude\"] = ((df_dataset[\"latitude\"]-df_dataset[\"latitude\"].min())/(df_dataset[\"latitude\"].max()-df_dataset[\"latitude\"].min()))\n",
        "\n",
        "df_dataset[\"longitude\"] = ((df_dataset[\"longitude\"]-df_dataset[\"longitude\"].min())/(df_dataset[\"longitude\"].max()-df_dataset[\"longitude\"].min()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voWNvyrKhzon"
      },
      "source": [
        "plt.figure(num=None, figsize=(20, 14), dpi=80, facecolor='w', edgecolor='k')\n",
        "\n",
        "plt.subplot(3, 3, 1)\n",
        "plt.hist(df_dataset[\"minimum_nights\"], bins=50)\n",
        "plt.title(\"minimum_nights\")\n",
        "\n",
        "plt.subplot(3, 3, 2)\n",
        "plt.hist(df_dataset[\"number_of_reviews\"], bins=50)\n",
        "plt.title(\"number_of_reviews\")\n",
        "\n",
        "plt.subplot(3, 3, 3)\n",
        "plt.hist(df_dataset[\"reviews_per_month\"], bins=50)\n",
        "plt.title(\"reviews_per_month\")\n",
        "\n",
        "plt.subplot(3, 3, 4)\n",
        "plt.hist(df_dataset[\"calculated_host_listings_count\"], bins=50)\n",
        "plt.title(\"calculated_host_listings_count\")\n",
        "\n",
        "plt.subplot(3, 3, 5)\n",
        "plt.hist(df_dataset[\"availability_365\"])\n",
        "plt.title(\"availability_365\")\n",
        "\n",
        "plt.subplot(3, 3, 6)\n",
        "plt.hist(df_dataset[\"Private_room\"])\n",
        "plt.title(\"Private_room\")\n",
        "\n",
        "plt.subplot(3, 3, 7)\n",
        "plt.hist(df_dataset[\"Entire_home/apt\"])\n",
        "plt.title(\"Entire_home/apt\")\n",
        "\n",
        "plt.subplot(3, 3, 8)\n",
        "plt.hist(df_dataset[\"price\"], 100)\n",
        "plt.title(\"price\")\n",
        "\n",
        "plt.subplot(3, 3, 9)\n",
        "plt.plot(df_dataset[\"latitude\"], df_dataset[\"longitude\"], \"ro\")\n",
        "plt.xlabel(\"latitude\")\n",
        "plt.ylabel(\"longitude\")\n",
        "plt.title(\"geo position\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvs-ED6yh3At"
      },
      "source": [
        "<hr><h3>Regression</h3><hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL8qmmwQh8fI"
      },
      "source": [
        "# split dataset in train and test sets\n",
        "df_train, df_test = train_test_split(df_dataset, test_size=0.10, random_state=123)\n",
        "\n",
        "# set of activation functions\n",
        "get_custom_objects().update({'leaky-relu(alpha=0.3)': Activation(LeakyReLU(alpha=0.3))})\n",
        "get_custom_objects().update({'leaky-relu(alpha=0.2)': Activation(LeakyReLU(alpha=0.2))})\n",
        "get_custom_objects().update({'leaky-relu(alpha=0.1)': Activation(LeakyReLU(alpha=0.1))})\n",
        "act_func = ['relu', 'elu', 'leaky-relu(alpha=0.3)', 'leaky-relu(alpha=0.2)', 'leaky-relu(alpha=0.1)', 'selu', 'swish']\n",
        "\n",
        "result = []\n",
        "for act in act_func:\n",
        "  print(\"\\nEvaluating ...\", act)\n",
        "  nfeatures = df_train.shape[1] - 1\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=(nfeatures,)))\n",
        "  model.add(Dense(14, activation=\"relu\"))\n",
        "  model.add(Dense(14, activation=\"relu\"))\n",
        "  model.add(Dense(14, activation=\"relu\"))\n",
        "  model.add(Dense(14, activation=\"relu\"))\n",
        "  model.add(Dense(1, activation=act))\n",
        "  model.compile(optimizer=\"adam\", loss='mse', metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "  history = model.fit(np.array(df_train)[:,:-1], np.array(df_train)[:,-1],\n",
        "          batch_size=1024,\n",
        "          epochs=1000,\n",
        "          verbose=0,\n",
        "          validation_data=(np.array(df_test)[:,:-1], np.array(df_test)[:,-1]))\n",
        "  \n",
        "  result.append(history) \n",
        "  \n",
        "  K.clear_session()\n",
        "  del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epwFUYgygEvn"
      },
      "source": [
        "# Plot of the validation root mean squared error vs\n",
        "## the train root mean squared error\n",
        "plt.figure(figsize=(16,30))\n",
        "    \n",
        "rmse_finale_val = []\n",
        "rmse_finale_tr = []\n",
        "counter=1\n",
        "for act_function in result:\n",
        "  plt.subplot(5, 2, counter)\n",
        "  plt.ylabel('RMSE')\n",
        "  plt.xlabel('Epochs') \n",
        "  plt.title(act_func[counter - 1])\n",
        "  plt.plot(act_function.history['val_root_mean_squared_error'])\n",
        "  rmse_finale_val.append(act_function.history['val_root_mean_squared_error'][-1])\n",
        "  plt.plot(act_function.history['root_mean_squared_error'])\n",
        "  rmse_finale_tr.append(act_function.history['root_mean_squared_error'][-1])\n",
        "  counter += 1\n",
        "    \n",
        "plt.show()\n",
        "\n",
        "for i in range(len(act_func)):\n",
        "  print('Validation RMSE of the activation function {} is {}'.format(act_func[i], round(rmse_finale_val[i], 5)))\n",
        "  print('Train RMSE of the activation function {} is {}'.format(act_func[i], round(rmse_finale_tr[i], 5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmQxXweZvSdH"
      },
      "source": [
        "<hr>\n",
        "<h3>Build the model with the whole dataset</h3>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VHwRMqDvQ9w"
      },
      "source": [
        "nfeatures = df_dataset.shape[1] - 1\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(nfeatures,)))\n",
        "model.add(Dense(14, activation=\"relu\"))\n",
        "model.add(Dense(14, activation=\"relu\"))\n",
        "model.add(Dense(14, activation=\"relu\"))\n",
        "model.add(Dense(14, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"relu\"))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model.fit(np.array(df_dataset)[:,:-1], np.array(df_dataset)[:,-1],\n",
        "          batch_size=1024,\n",
        "          epochs=500,\n",
        "          verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKYqjRLzxPZe"
      },
      "source": [
        "<hr><h3>Preprocess X_test</h3><hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uly3LFvxxUJ0"
      },
      "source": [
        "df_x_test= pd.read_csv(\"X_test.csv\")\n",
        "df_x_test = df_x_test.drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "# apply log(x + 1) transformation and normalize between 0 and 1\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "df_x_test[\"minimum_nights\"] = np.log(df_x_test[\"minimum_nights\"] + 1)\n",
        "df_x_test[\"minimum_nights\"] = ((df_x_test[\"minimum_nights\"]-df_x_test[\"minimum_nights\"].min())/(df_x_test[\"minimum_nights\"].max()-df_x_test[\"minimum_nights\"].min()))\n",
        "\n",
        "df_x_test[\"number_of_reviews\"] = np.log(df_x_test[\"number_of_reviews\"] + 1)\n",
        "df_x_test[\"number_of_reviews\"] = ((df_x_test[\"number_of_reviews\"]-df_x_test[\"number_of_reviews\"].min())/(df_x_test[\"number_of_reviews\"].max()-df_x_test[\"number_of_reviews\"].min()))\n",
        "\n",
        "df_x_test[\"reviews_per_month\"] = np.log(df_x_test[\"reviews_per_month\"] + 1)\n",
        "df_x_test[\"reviews_per_month\"] = ((df_x_test[\"reviews_per_month\"]-df_x_test[\"reviews_per_month\"].min())/(df_x_test[\"reviews_per_month\"].max()-df_x_test[\"reviews_per_month\"].min()))\n",
        "\n",
        "df_x_test[\"calculated_host_listings_count\"] = np.log(df_x_test[\"calculated_host_listings_count\"] + 1)\n",
        "df_x_test[\"calculated_host_listings_count\"] = ((df_x_test[\"calculated_host_listings_count\"]-df_x_test[\"calculated_host_listings_count\"].min())/(df_x_test[\"calculated_host_listings_count\"].max()-df_x_test[\"calculated_host_listings_count\"].min()))\n",
        "\n",
        "df_x_test[\"availability_365\"] = np.log(df_x_test[\"availability_365\"] + 1)\n",
        "df_x_test[\"availability_365\"] = ((df_x_test[\"availability_365\"]-df_x_test[\"availability_365\"].min())/(df_x_test[\"availability_365\"].max()-df_x_test[\"availability_365\"].min()))\n",
        "\n",
        "df_x_test[\"latitude\"] = ((df_x_test[\"latitude\"]-df_x_test[\"latitude\"].min())/(df_x_test[\"latitude\"].max()-df_x_test[\"latitude\"].min()))\n",
        "\n",
        "df_x_test[\"longitude\"] = ((df_x_test[\"longitude\"]-df_x_test[\"longitude\"].min())/(df_x_test[\"longitude\"].max()-df_x_test[\"longitude\"].min()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcfxHFFaw6EV"
      },
      "source": [
        "<hr><h3>Predict the prices on X_test</h3><hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUrOgKb1w_1m"
      },
      "source": [
        "predictions = np.transpose(model.predict(np.array(df_x_test))).flatten()\n",
        "\n",
        "file = open(\"Simone_Paolo_Mottadelli_820786_score1.txt\", \"w\")\n",
        "for i in range(0, len(predictions)):\n",
        "  file.write(str(int(np.round(predictions[i]))) + \"\\n\")\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}